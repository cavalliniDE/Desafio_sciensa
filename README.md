A escolha da ferramenta StreamSets foi tomada devido a sua facilidade de conexão com diversas fontes de dados, sua velocidade de transformação de dados e carga. Além do  schedule na própria ferramenta , garantem a periodicidade da ingestão pré-definida pelo desenvolvedor. 
Levando os dados ao data lake , on-premise ou nuvem.

Gostaria de deixar alguns adendos , sobre a tratativa do desafio técnico:
Toda estrutura foi criada na Nuvem pela ferramenta Spark databricks , a extensão de arquivos é .DBC podendo ser abertos por notebooks no formato .IPYNB
o ideal é abrir o arquivo na propria ferramenta databricks comunnity
www.Logincommunity.cloud.databricks.com
Alguns comandos são da própria ferramenta. Não iram executar diretamente no Python.
O comando spark-subit não irá se aplicar neste caso, para execução do código.
utilizei alguns comandos com limit e take , para limitar a exibição de linhas
Qualquer dúvida , fico a disposição.
Att. Bruno Milhati Cavallini
